name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  # Paths
  SOURCE_DIR: "src"
  TEST_DIR: "tests"

  # Quality thresholds
  COVERAGE_THRESHOLD: "85"

  # Retention policies
  ARTIFACT_RETENTION_DAYS: "90"
  IMAGE_RETENTION_DAYS: "30"

  # Python version for quality/sonarcloud jobs
  PRIMARY_PYTHON_VERSION: "3.11"

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065  # v5.6.0
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-dev.txt

      - name: Lint with ruff
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          ruff check src/ tests/ > ruff-lint.txt 2>&1
          EXIT_CODE=$?
          echo "" >> ruff-lint.txt
          echo "Exit code: ${EXIT_CODE}" >> ruff-lint.txt
          exit ${EXIT_CODE}

      - name: Check formatting with ruff
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          ruff format --check src/ tests/ > ruff-format.txt 2>&1
          EXIT_CODE=$?
          echo "" >> ruff-format.txt
          echo "Exit code: ${EXIT_CODE}" >> ruff-format.txt
          exit ${EXIT_CODE}

      - name: Type check with mypy
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          mypy src/sparsetag.py src/cache_manager.py src/exceptions.py > mypy-report.txt 2>&1
          EXIT_CODE=$?
          echo "" >> mypy-report.txt
          echo "Exit code: ${EXIT_CODE}" >> mypy-report.txt
          exit ${EXIT_CODE}

      - name: Upload quality reports
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: quality-reports
          path: |
            ruff-lint.txt
            ruff-format.txt
            mypy-report.txt
          retention-days: 90

  sonarcloud:
    name: SonarCloud Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: quality
    environment: CGB
    permissions:
      contents: read
      pull-requests: read
    env:
      GITHUB_TOKEN: ${{ github.token }}
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-dev.txt

      - name: Run tests with coverage
        run: |
          pytest tests/ --cov=src --cov-report=xml --cov-report=term-missing -v

      - name: Verify SONAR_TOKEN is available
        id: check_sonar
        shell: bash
        run: |
          if [ -z "${SONAR_TOKEN}" ]; then
            echo "::warning::SONAR_TOKEN is empty. SonarCloud scan will be skipped."
            echo "available=false" >> $GITHUB_OUTPUT
          else
            echo "SONAR_TOKEN is set (masked)."
            echo "available=true" >> $GITHUB_OUTPUT
          fi
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

      - name: SonarCloud Scan
        if: steps.check_sonar.outputs.available == 'true'
        uses: SonarSource/sonarcloud-github-action@ffc3010689be73b8e5ae0c57ce35968afd7909e8

      - name: Upload coverage report
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: coverage-report
          path: coverage.xml
          retention-days: 90

  service-health-check:
    name: Service Health Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Check external service availability
        continue-on-error: true
        run: |
          echo "Checking service health..."

          # Check PyPI (accept 200)
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://pypi.org/simple/)
          if [[ "$STATUS" == "200" ]]; then
            echo "âœ… PyPI is reachable (HTTP $STATUS)"
          else
            echo "::warning::PyPI returned HTTP $STATUS"
          fi

          # Check Docker Hub (accept 200 or 3xx redirects)
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://hub.docker.com/)
          if [[ "$STATUS" =~ ^(200|3[0-9]{2})$ ]]; then
            echo "âœ… Docker Hub is reachable (HTTP $STATUS)"
          else
            echo "::warning::Docker Hub returned HTTP $STATUS"
          fi

          # Check SonarCloud (accept 200 or 3xx redirects)
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://sonarcloud.io/)
          if [[ "$STATUS" =~ ^(200|3[0-9]{2})$ ]]; then
            echo "âœ… SonarCloud is reachable (HTTP $STATUS)"
          else
            echo "::warning::SonarCloud returned HTTP $STATUS"
          fi

          # Check GHCR (accept 200, 3xx, or 405 - all indicate service is up)
          # Note: GHCR returns 405 for HEAD requests on root, which is normal
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://ghcr.io/)
          if [[ "$STATUS" =~ ^(200|3[0-9]{2}|405)$ ]]; then
            echo "âœ… GHCR is reachable (HTTP $STATUS)"
          else
            echo "::warning::GHCR returned HTTP $STATUS"
          fi

  test:
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 5
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        python-version: ["3.10", "3.11", "3.12", "3.13"]

    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065  # v5.6.0
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-dev.txt

      - name: Test with pytest
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          pytest tests/ --cov=src --cov-report=xml --cov-report=term-missing --cov-fail-under=85 -v --junitxml=pytest-results.xml > pytest-output.txt 2>&1
          EXIT_CODE=$?
          echo "" >> pytest-output.txt
          echo "Exit code: ${EXIT_CODE}" >> pytest-output.txt
          exit ${EXIT_CODE}

      - name: Upload test results
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: |
            pytest-output.txt
            pytest-results.xml
            coverage.xml
          retention-days: 90

      - name: Check CODECOV_TOKEN availability
        id: check_codecov
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        shell: bash
        run: |
          if [ -z "${CODECOV_TOKEN}" ]; then
            echo "::warning::CODECOV_TOKEN is empty. Coverage upload will be skipped."
            echo "available=false" >> $GITHUB_OUTPUT
          else
            echo "CODECOV_TOKEN is set (masked)."
            echo "available=true" >> $GITHUB_OUTPUT
          fi
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload coverage to Codecov
        if: |
          matrix.os == 'ubuntu-latest' &&
          matrix.python-version == '3.11' &&
          steps.check_codecov.outputs.available == 'true'
        uses: codecov/codecov-action@b9fd7d16f6d7d1b5d2bec1a2887e65ceed900238  # v4
        continue-on-error: true  # Don't fail CI if CodeCov upload fails
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          fail_ci_if_error: false
          verbose: true

  docker-build-scan:
    name: Docker Build & Scan
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [quality, test]
    permissions:
      contents: write  # Changed from 'read' to allow committing scan results
      packages: write
      security-events: write
      actions: read  # Required for SARIF upload

    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4.3.1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}  # Ensure we can push back to repo

      - name: Extract version from pyproject.toml
        id: get_version
        run: |
          VERSION=$(python3 .github/scripts/extract-version.py)
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "Extracted version: ${VERSION}"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@988b5a0280414f521da01fcc63a27aeeb4b104db  # v3.7.1

      - name: Build Docker image
        uses: docker/build-push-action@48aba3b46d1b1fec4febb7c5d0c644b249a11355  # v6.10.0
        with:
          context: .
          push: false
          load: true
          tags: sparsetagging:${{ github.sha }}
          build-args: |
            APP_VERSION=${{ steps.get_version.outputs.version }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Run Trivy vulnerability scanner (SARIF)
        uses: aquasecurity/trivy-action@18f2510ee396bbf400402947b394f2dd8c87dbb0  # master
        continue-on-error: true  # Don't fail if vulnerabilities found, we want the SARIF file
        with:
          image-ref: sparsetagging:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          scanners: 'vuln,secret,config'  # Scan for vulnerabilities, secrets, and misconfigs
          exit-code: '0'  # Don't exit on findings, just create the report

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@ea9e4e37992a54ee68a9622e985e60c8e8f12d9f  # v3.27.6
        if: always()
        continue-on-error: true  # Will fail until Code Scanning is enabled in repo settings
        with:
          sarif_file: 'trivy-results.sarif'
          # To enable: Settings â†’ Code security â†’ Enable Code scanning

      - name: Upload Trivy SARIF report as artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: trivy-sarif-report
          path: trivy-results.sarif
          retention-days: 90

      - name: Run Trivy for full report (informational)
        uses: aquasecurity/trivy-action@18f2510ee396bbf400402947b394f2dd8c87dbb0  # master
        continue-on-error: true  # Don't fail build on vulnerabilities (base image issues)
        with:
          image-ref: sparsetagging:${{ github.sha }}
          format: 'table'
          output: 'trivy-report.txt'  # Save table report to file
          exit-code: '0'  # Report vulnerabilities but don't fail the build
          severity: 'CRITICAL,HIGH,MEDIUM'
          scanners: 'vuln,secret,config'  # Comprehensive scanning

      - name: Upload Trivy table report as artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: trivy-vulnerability-report
          path: trivy-report.txt
          retention-days: 90

      - name: Generate SBOM
        uses: aquasecurity/trivy-action@18f2510ee396bbf400402947b394f2dd8c87dbb0  # master
        with:
          image-ref: sparsetagging:${{ github.sha }}
          format: 'spdx-json'
          output: 'sbom.spdx.json'

      - name: Upload SBOM artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: sbom
          path: sbom.spdx.json
          retention-days: 90

      - name: Export Docker image as tarball
        run: |
          docker save sparsetagging:${{ github.sha }} -o sparsetagging-${{ github.sha }}.tar
          gzip sparsetagging-${{ github.sha }}.tar

      - name: Upload Docker image as artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        with:
          name: docker-image
          path: sparsetagging-${{ github.sha }}.tar.gz
          retention-days: 30  # Shorter retention for large files

      - name: Generate artifact summary
        run: |
          cat > artifact-summary.md << 'EOF'
          # SparseTagging Docker Build Artifacts

          **Build Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Commit SHA:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## Available Artifacts

          ### 1. Docker Image (`docker-image`)
          - **File:** `sparsetagging-${{ github.sha }}.tar.gz`
          - **Size:** ~300MB (compressed)
          - **Usage:**
            ```bash
            # Download and load the image
            gunzip sparsetagging-${{ github.sha }}.tar.gz
            docker load -i sparsetagging-${{ github.sha }}.tar

            # Run the image
            docker run --rm sparsetagging:${{ github.sha }}

            # Interactive shell
            docker run --rm -it sparsetagging:${{ github.sha }} /bin/bash
            ```

          ### 2. Trivy Vulnerability Report (`trivy-vulnerability-report`)
          - **File:** `trivy-report.txt`
          - **Format:** Human-readable table
          - **Severities:** CRITICAL, HIGH, MEDIUM
          - **Scans:** Vulnerabilities, Secrets, Misconfigurations
          - **Usage:** Open in text editor to review findings

          ### 3. Trivy SARIF Report (`trivy-sarif-report`)
          - **File:** `trivy-results.sarif`
          - **Format:** SARIF (machine-readable)
          - **Usage:** Import into security tools, IDEs, or GitHub Security

          ### 4. SBOM - Software Bill of Materials (`sbom`)
          - **File:** `sbom.spdx.json`
          - **Format:** SPDX JSON
          - **Usage:** Compliance, license tracking, supply chain security
            ```bash
            # View with Trivy
            trivy sbom sbom.spdx.json

            # Validate SPDX
            java -jar spdx-tools.jar Verify sbom.spdx.json
            ```

          ## Image Details

          - **Base Image:** python:3.11-slim
          - **Architecture:** linux/amd64
          - **User:** sparsetag (UID 1000, non-root)
          - **Working Directory:** /app
          - **Python Version:** 3.11
          - **SparseTagging Version:** ${{ steps.get_version.outputs.version }}

          ## Testing the Image

          ```bash
          # Load the image
          docker load -i sparsetagging-${{ github.sha }}.tar

          # Verify it works
          docker run --rm sparsetagging:${{ github.sha }} python -c "import sparsetagging; print('OK')"

          # Run benchmarks (if available)
          docker run --rm sparsetagging:${{ github.sha }} python -m pytest --version
          ```

          ## Security Review

          1. **Review vulnerabilities:** Check `trivy-report.txt`
          2. **Check SARIF:** Import `trivy-results.sarif` to IDE
          3. **Verify SBOM:** Review `sbom.spdx.json` for dependencies
          4. **Test image:** Load and run security scans locally

          ## GitHub Container Registry

          On main branch, this image is also published to:
          ```
          ghcr.io/cgbraun/sparsetagging:latest
          ghcr.io/cgbraun/sparsetagging:${{ steps.get_version.outputs.version }}
          ```

          Pull and use:
          ```bash
          docker pull ghcr.io/cgbraun/sparsetagging:latest
          docker run --rm ghcr.io/cgbraun/sparsetagging:latest
          ```
          EOF

      - name: Upload artifact summary
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: artifact-summary
          path: artifact-summary.md
          retention-days: 90

      - name: Download quality reports
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        if: github.ref == 'refs/heads/main'
        continue-on-error: true
        with:
          name: quality-reports
          path: ./quality-reports/

      - name: Download coverage report
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        if: github.ref == 'refs/heads/main'
        continue-on-error: true
        with:
          name: coverage-report
          path: ./coverage-report/

      - name: Download all test results
        uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16  # v4.1.8
        if: github.ref == 'refs/heads/main'
        continue-on-error: true
        with:
          pattern: test-results-*
          path: ./test-results/
          merge-multiple: false

      - name: Save security artifacts to repository (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          # Create timestamped directory
          TIMESTAMP=$(date -u +"%Y-%m-%d_%H-%M-%S")
          SCAN_DIR="ScanResults/${TIMESTAMP}"
          mkdir -p "${SCAN_DIR}"

          # Copy security artifacts
          cp trivy-results.sarif "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ trivy-results.sarif not found"
          cp trivy-report.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ trivy-report.txt not found"
          cp sbom.spdx.json "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ sbom.spdx.json not found"

          # Copy code quality reports
          cp quality-reports/ruff-lint.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ ruff-lint.txt not found"
          cp quality-reports/ruff-format.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ ruff-format.txt not found"
          cp quality-reports/mypy-report.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ mypy-report.txt not found"
          cp coverage-report/coverage.xml "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ coverage.xml not found"

          # Create test summary from all test matrix results
          cat > "${SCAN_DIR}/test-summary.md" << TEST_SUMMARY
          # Test Results Summary

          **Test Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Test Matrix:** Python 3.10, 3.11, 3.12, 3.13 Ã— Ubuntu + Windows

          ---

          ## Test Results by Environment

          TEST_SUMMARY

          # Parse test results from each matrix run
          if [ -d "test-results" ]; then
            for test_dir in test-results/test-results-*; do
              if [ -d "$test_dir" ]; then
                os_py=$(basename "$test_dir" | sed 's/test-results-//')
                echo "" >> "${SCAN_DIR}/test-summary.md"
                echo "### $os_py" >> "${SCAN_DIR}/test-summary.md"
                echo "" >> "${SCAN_DIR}/test-summary.md"

                if [ -f "$test_dir/pytest-output.txt" ]; then
                  # Extract key metrics
                  if grep -q "passed" "$test_dir/pytest-output.txt"; then
                    grep -E "(passed|failed|error|skipped|warnings summary)" "$test_dir/pytest-output.txt" | tail -5 >> "${SCAN_DIR}/test-summary.md"
                  else
                    echo "âš ï¸ Test output not parseable" >> "${SCAN_DIR}/test-summary.md"
                  fi
                  echo "" >> "${SCAN_DIR}/test-summary.md"
                fi
              fi
            done
          fi

          cat >> "${SCAN_DIR}/test-summary.md" << 'TEST_FOOTER'

          ---

          ## Full Test Outputs

          Individual test outputs for each environment are available in the \`test-results/\` directory.

          TEST_FOOTER

          # Parse vulnerability counts from Trivy SARIF (accurate count of unique vulnerabilities)
          if [ -f "${SCAN_DIR}/trivy-results.sarif" ]; then
            # Count unique vulnerabilities by severity from SARIF tags array
            # Note: Trivy stores vulnerabilities in .runs[].tool.driver.rules[], not .runs[].results[]
            CRITICAL_COUNT=$(jq '[.runs[].tool.driver.rules[]? | select(.properties.tags[]? == "CRITICAL")] | length' "${SCAN_DIR}/trivy-results.sarif" 2>/dev/null || echo "0")
            HIGH_COUNT=$(jq '[.runs[].tool.driver.rules[]? | select(.properties.tags[]? == "HIGH")] | length' "${SCAN_DIR}/trivy-results.sarif" 2>/dev/null || echo "0")
            MEDIUM_COUNT=$(jq '[.runs[].tool.driver.rules[]? | select(.properties.tags[]? == "MEDIUM")] | length' "${SCAN_DIR}/trivy-results.sarif" 2>/dev/null || echo "0")
            LOW_COUNT=$(jq '[.runs[].tool.driver.rules[]? | select(.properties.tags[]? == "LOW")] | length' "${SCAN_DIR}/trivy-results.sarif" 2>/dev/null || echo "0")
          elif [ -f "${SCAN_DIR}/trivy-report.txt" ]; then
            # Fallback to text parsing if SARIF unavailable (less accurate)
            echo "::warning::Using text-based vulnerability counting (less accurate). SARIF file preferred."
            CRITICAL_COUNT=$(grep -c "CRITICAL" "${SCAN_DIR}/trivy-report.txt" 2>/dev/null || echo "0")
            HIGH_COUNT=$(grep -c "HIGH" "${SCAN_DIR}/trivy-report.txt" 2>/dev/null || echo "0")
            MEDIUM_COUNT=$(grep -c "MEDIUM" "${SCAN_DIR}/trivy-report.txt" 2>/dev/null || echo "0")
            LOW_COUNT=$(grep -c "LOW" "${SCAN_DIR}/trivy-report.txt" 2>/dev/null || echo "0")
          else
            echo "::warning::trivy-results.sarif not found, vulnerability counts unavailable"
            CRITICAL_COUNT="N/A"
            HIGH_COUNT="N/A"
            MEDIUM_COUNT="N/A"
            LOW_COUNT="N/A"
          fi

          # Parse quality gate results from downloaded artifacts
          RUFF_LINT_EXIT="N/A"
          RUFF_FORMAT_EXIT="N/A"
          MYPY_EXIT="N/A"
          if [ -f "quality-reports/ruff-lint.txt" ]; then
            RUFF_LINT_EXIT=$(grep "Exit code:" quality-reports/ruff-lint.txt | tail -1 | awk '{print $NF}' || echo "N/A")
          fi
          if [ -f "quality-reports/ruff-format.txt" ]; then
            RUFF_FORMAT_EXIT=$(grep "Exit code:" quality-reports/ruff-format.txt | tail -1 | awk '{print $NF}' || echo "N/A")
          fi
          if [ -f "quality-reports/mypy-report.txt" ]; then
            MYPY_EXIT=$(grep "Exit code:" quality-reports/mypy-report.txt | tail -1 | awk '{print $NF}' || echo "N/A")
          fi

          # Count test matrix results
          TOTAL_TEST_RUNS=0
          PASSED_TEST_RUNS=0
          if [ -d "test-results" ]; then
            for test_dir in test-results/test-results-*; do
              if [ -d "$test_dir" ]; then
                TOTAL_TEST_RUNS=$((TOTAL_TEST_RUNS + 1))
                if [ -f "$test_dir/pytest-output.txt" ]; then
                  # Check if tests passed (exit code 0)
                  if grep -q "Exit code: 0" "$test_dir/pytest-output.txt" 2>/dev/null; then
                    PASSED_TEST_RUNS=$((PASSED_TEST_RUNS + 1))
                  fi
                fi
              fi
            done
          fi

          # Parse Docker smoke test results (only on main branch)
          SMOKE_TEST_AVAILABLE="false"
          SMOKE_TEST1_STATUS="N/A"
          SMOKE_TEST2_STATUS="N/A"
          SMOKE_TEST3_STATUS="N/A"
          SMOKE_VERSION="N/A"
          if [ -f "docker-smoke-test-results.txt" ]; then
            SMOKE_TEST_AVAILABLE="true"
            SMOKE_TEST1_STATUS=$(grep "TEST1=" docker-smoke-test-results.txt | cut -d= -f2 || echo "N/A")
            SMOKE_TEST2_STATUS=$(grep "TEST2=" docker-smoke-test-results.txt | cut -d= -f2 || echo "N/A")
            SMOKE_TEST3_STATUS=$(grep "TEST3=" docker-smoke-test-results.txt | cut -d= -f2 || echo "N/A")
            SMOKE_VERSION=$(grep "VERSION=" docker-smoke-test-results.txt | cut -d= -f2 || echo "N/A")
          fi

          # Generate README.md summary
          cat > "${SCAN_DIR}/README.md" << README_EOF
          # Security Scan Results

          **Scan Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Commit SHA:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          **Workflow Run:** https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
          **SonarCloud:** https://sonarcloud.io/project/overview?id=cgbraun_SparseTagging

          ---

          ## CI Pipeline Execution Summary

          ### Quality Gate Results

          | Check | Exit Code | Status |
          |-------|-----------|--------|
          | Ruff Lint | ${RUFF_LINT_EXIT} | $([ "${RUFF_LINT_EXIT}" = "0" ] && echo "âœ… Passed" || echo "âš ï¸ Issues Found") |
          | Ruff Format | ${RUFF_FORMAT_EXIT} | $([ "${RUFF_FORMAT_EXIT}" = "0" ] && echo "âœ… Passed" || echo "âš ï¸ Issues Found") |
          | Mypy Type Check | ${MYPY_EXIT} | $([ "${MYPY_EXIT}" = "0" ] && echo "âœ… Passed" || echo "âš ï¸ Issues Found") |

          > **Note:** Exit code 0 = passed. Non-zero = issues found. See individual report files for details.

          ### Test Matrix Results

          - **Total Test Runs:** ${TOTAL_TEST_RUNS} (Python 3.10-3.13 Ã— Ubuntu/Windows)
          - **Passed:** ${PASSED_TEST_RUNS}
          - **Failed:** $((TOTAL_TEST_RUNS - PASSED_TEST_RUNS))
          - **Details:** See \`test-summary.md\` for per-environment results

          ### Service Health Checks

          The following external services were checked for availability:
          - PyPI (package downloads)
          - Docker Hub (base images)
          - SonarCloud (code quality analysis)
          - GitHub Container Registry (image publishing)

          > **View Results:** Check [workflow run logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) â†’ "Service Health Check" job

          $(if [ "${SMOKE_TEST_AVAILABLE}" = "true" ]; then
            cat << SMOKE_EOF

          ### Docker Image Smoke Tests

          | Test | Status |
          |------|--------|
          | Import Verification | $([ "${SMOKE_TEST1_STATUS}" = "PASSED" ] && echo "âœ… Passed" || echo "âŒ Failed") |
          | Version Check | $([ "${SMOKE_TEST2_STATUS}" = "PASSED" ] && echo "âœ… Passed (${SMOKE_VERSION})" || echo "âŒ Failed") |
          | Basic Functionality | $([ "${SMOKE_TEST3_STATUS}" = "PASSED" ] && echo "âœ… Passed" || echo "âŒ Failed") |

          > **Note:** Docker smoke tests only run on main branch before pushing to GHCR.
SMOKE_EOF
          else
            echo ""
            echo "> **Note:** Docker smoke tests only run on main branch (not executed for this build)."
          fi)

          ---

          ## Vulnerability Summary (Trivy)

          | Severity | Count |
          |----------|-------|
          | CRITICAL | ${CRITICAL_COUNT} |
          | HIGH     | ${HIGH_COUNT} |
          | MEDIUM   | ${MEDIUM_COUNT} |
          | LOW      | ${LOW_COUNT} |

          > **Note:** Counts are approximate based on keyword matching. See trivy-report.txt for full details.

          ---

          ## Available Files

          ### 1. \`trivy-results.sarif\`
          - **Format:** SARIF (Static Analysis Results Interchange Format)
          - **Purpose:** Machine-readable security findings
          - **Usage:**
            - Import into VS Code, PyCharm, or other IDEs with SARIF support
            - Upload to GitHub Security tab (Code Scanning)
            - Process with automated security tools
          - **Contains:** Vulnerabilities, secrets, misconfigurations
          - **Severity Filter:** CRITICAL, HIGH only

          ### 2. \`trivy-report.txt\`
          - **Format:** Human-readable table
          - **Purpose:** Quick visual review of all vulnerabilities
          - **Usage:** Open in text editor to review findings
          - **Contains:** Vulnerabilities, secrets, misconfigurations
          - **Severity Filter:** CRITICAL, HIGH, MEDIUM

          ### 3. \`sbom.spdx.json\`
          - **Format:** SPDX 2.3 JSON
          - **Purpose:** Software Bill of Materials for compliance and supply chain security
          - **Usage:**
            \`\`\`bash
            # View with Trivy
            trivy sbom sbom.spdx.json

            # Validate SPDX format
            # (requires spdx-tools: https://github.com/spdx/tools)
            java -jar spdx-tools.jar Verify sbom.spdx.json
            \`\`\`
          - **Contains:** All packages, versions, licenses, dependencies


          ### 4. \`coverage.xml\`
          - **Format:** Cobertura XML
          - **Purpose:** Code coverage metrics from pytest
          - **Usage:** Import into IDEs, coverage visualization tools
          - **Contains:** Line-by-line coverage data for all source files

          ### 5. \`test-summary.md\`
          - **Format:** Markdown summary report
          - **Purpose:** Consolidated test results from all Python versions and platforms
          - **Contains:** Pass/fail status for Python 3.10-3.13 on Ubuntu and Windows

          ### 6. \`ruff-lint.txt\`
          - **Format:** Plain text
          - **Purpose:** Linting results from ruff
          - **Contains:** Code style violations, unused imports, complexity issues

          ### 7. \`ruff-format.txt\`
          - **Format:** Plain text
          - **Purpose:** Code formatting check results
          - **Contains:** Files that need formatting, formatting violations

          ### 8. \`mypy-report.txt\`
          - **Format:** Plain text
          - **Purpose:** Static type checking results
          - **Contains:** Type errors, missing annotations, type mismatches

          ---

          ## SonarCloud Code Quality & Security

          **Project:** SparseTagging | **Commit:** ${{ github.sha }} | **Branch:** ${{ github.ref_name }}

          - ðŸ”’ **[Security Vulnerabilities](https://sonarcloud.io/project/issues?id=cgbraun_SparseTagging&resolved=false&types=VULNERABILITY)** - Unresolved security issues
          - âš ï¸ **[Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=cgbraun_SparseTagging)** - Security-sensitive code for review
          - ðŸ› **[Bugs & Code Smells](https://sonarcloud.io/project/issues?id=cgbraun_SparseTagging&resolved=false)** - All quality issues
          - ðŸ“ˆ **[Code Coverage Details](https://sonarcloud.io/component_measures?id=cgbraun_SparseTagging&metric=coverage&view=list)** - Line and branch coverage

          ---

          ## How to Use These Results

          ### Quick Security & Quality Review

          1. **Security Vulnerabilities:** Check SonarCloud security links above + `trivy-report.txt`
          2. **Tests:** Review `test-summary.md` for test pass/fail status
          3. **Code Quality:** Check SonarCloud bugs/code smells + `ruff-lint.txt` and `mypy-report.txt`
          4. **Coverage:** Review `coverage.xml` metrics (should be â‰¥85%)
          5. **SBOM:** Review `sbom.spdx.json` for dependencies

          ### Detailed Analysis

          1. **Import SARIF to IDE:**
             - VS Code: Install "SARIF Viewer" extension
             - PyCharm: Settings â†’ Tools â†’ SARIF â†’ Import `trivy-results.sarif`

          2. **GitHub Security Tab:**
             - Go to repository Security tab â†’ Code Scanning
             - Results from SARIF upload appear here

          3. **Compare with Previous Scans:**
             - Check `ScanResults/` directory for historical scans
             - Compare vulnerability counts over time

          ---

          ## Docker Image Details

          - **Base Image:** python:3.11-slim (Debian)
          - **Application:** SparseTagging v2.4.1
          - **Python Version:** 3.11
          - **User:** sparsetag (non-root, UID 1000)
          - **Architecture:** linux/amd64

          ---

          ## Next Steps

          If vulnerabilities are found:

          1. **Assess Impact:** Check if the CVE affects SparseTagging's use case
          2. **Check for Fixes:** See if updated base images or packages are available
          3. **Risk Assessment:** Document in SECURITY.md if no fix is available
          4. **Patch:** Update Dockerfile or requirements.txt as needed
          5. **Retest:** Push changes to trigger new security scan

          For questions about these results, see `SECURITY.md` in the repository root.
          README_EOF

          echo "âœ… Security artifacts saved to ${SCAN_DIR}/"
          ls -lah "${SCAN_DIR}/"

      - name: Commit and push security scan results (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          TIMESTAMP=$(date -u +"%Y-%m-%d_%H-%M-%S")

          git add ScanResults/

          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore(security): add scan results for ${TIMESTAMP}

          - Trivy vulnerability scan (SARIF and table formats)
          - SBOM in SPDX format
          - SonarCloud analysis links
          - Automated scan from commit ${{ github.sha }}

          ðŸ¤– Generated by GitHub Actions"

            git push
          fi

      - name: Verify Docker image exists
        if: github.ref == 'refs/heads/main'
        run: |
          if docker image inspect sparsetagging:${{ github.sha }} >/dev/null 2>&1; then
            echo "âœ… Docker image sparsetagging:${{ github.sha }} found"
            docker images sparsetagging:${{ github.sha }}
          else
            echo "::error::Docker image sparsetagging:${{ github.sha }} not found. Build may have failed."
            exit 1
          fi

      - name: Test Docker image (smoke test)
        if: github.ref == 'refs/heads/main'
        run: |
          echo "Running smoke test on Docker image..."

          # Save results to file for README
          SMOKE_TEST_RESULTS="docker-smoke-test-results.txt"

          # Test 1: Verify import works
          if docker run --rm sparsetagging:${{ github.sha }} python -c "import sparsetagging; print('âœ… Import successful')" > /tmp/test1.txt 2>&1; then
            cat /tmp/test1.txt | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST1=PASSED" >> "$SMOKE_TEST_RESULTS"
          else
            echo "âŒ Import failed" | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST1=FAILED" >> "$SMOKE_TEST_RESULTS"
          fi

          # Test 2: Verify version environment variable
          if docker run --rm sparsetagging:${{ github.sha }} python -c "import os; print(f'âœ… Version: {os.environ.get(\"APP_VERSION\", \"unknown\")}')" > /tmp/test2.txt 2>&1; then
            cat /tmp/test2.txt | tee -a "$SMOKE_TEST_RESULTS"
            VERSION_OUTPUT=$(cat /tmp/test2.txt | grep -oP 'Version: \K.*' || echo "unknown")
            echo "TEST2=PASSED" >> "$SMOKE_TEST_RESULTS"
            echo "VERSION=$VERSION_OUTPUT" >> "$SMOKE_TEST_RESULTS"
          else
            echo "âŒ Version check failed" | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST2=FAILED" >> "$SMOKE_TEST_RESULTS"
          fi

          # Test 3: Run basic functionality test
          if docker run --rm sparsetagging:${{ github.sha }} python -c "from sparsetagging import SparseTag, TagConfidence; st = SparseTag.create_random(100, ['Tag1', 'Tag2'], fill_percent=0.05); print(f'âœ… Created sparse matrix: {st.shape}')" > /tmp/test3.txt 2>&1; then
            cat /tmp/test3.txt | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST3=PASSED" >> "$SMOKE_TEST_RESULTS"
          else
            echo "âŒ Functionality test failed" | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST3=FAILED" >> "$SMOKE_TEST_RESULTS"
          fi

          echo "âœ… All smoke tests completed"
          echo "SMOKE_TEST_STATUS=COMPLETED" >> "$SMOKE_TEST_RESULTS"

      - name: Log in to GitHub Container Registry
        if: github.ref == 'refs/heads/main'
        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567  # v3.3.0
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Push to GHCR (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          docker tag sparsetagging:${{ github.sha }} ghcr.io/${{ github.repository_owner }}/sparsetagging:latest
          docker tag sparsetagging:${{ github.sha }} ghcr.io/${{ github.repository_owner }}/sparsetagging:${{ steps.get_version.outputs.version }}
          docker push ghcr.io/${{ github.repository_owner }}/sparsetagging:latest
          docker push ghcr.io/${{ github.repository_owner }}/sparsetagging:${{ steps.get_version.outputs.version }}
