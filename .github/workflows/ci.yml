name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  # Paths
  SOURCE_DIR: "src"
  TEST_DIR: "tests"

  # Quality thresholds
  COVERAGE_THRESHOLD: "85"

  # Retention policies
  ARTIFACT_RETENTION_DAYS: "90"
  IMAGE_RETENTION_DAYS: "30"

  # Python version for quality/sonarcloud jobs
  PRIMARY_PYTHON_VERSION: "3.11"

jobs:
  detect-changes:
    name: Detect File Changes
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      code: ${{ steps.filter.outputs.code }}
      docs: ${{ steps.filter.outputs.docs }}
      config: ${{ steps.filter.outputs.config }}
      workflows: ${{ steps.filter.outputs.workflows }}
      scan_results: ${{ steps.filter.outputs.scan_results }}
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8  # v6.0.1

      - uses: dorny/paths-filter@v3.0.2
        id: filter
        with:
          filters: |
            code:
              - 'src/**'
              - 'tests/**'
              - 'requirements*.txt'
              - 'pyproject.toml'
              - 'Dockerfile'
            docs:
              - 'docs/**'
              - '*.md'
              - '.claude/**'
              - 'tools/diagram-converter/**'
            config:
              - 'mypy.ini'
              - '.ruff.toml'
              - '.pre-commit-config.yaml'
              - 'sonar-project.properties'
            workflows:
              - '.github/workflows/**'
            scan_results:
              - 'ScanResults/**'

  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: detect-changes
    if: needs.detect-changes.outputs.code == 'true' || needs.detect-changes.outputs.config == 'true' || needs.detect-changes.outputs.workflows == 'true'
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8  # v6.0.1

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065  # v5.6.0
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-dev.txt

      - name: Lint with ruff
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          ruff check src/ tests/ > ruff-lint.txt 2>&1
          EXIT_CODE=$?
          echo "" >> ruff-lint.txt
          echo "Exit code: ${EXIT_CODE}" >> ruff-lint.txt
          exit ${EXIT_CODE}

      - name: Check formatting with ruff
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          ruff format --check src/ tests/ > ruff-format.txt 2>&1
          EXIT_CODE=$?
          echo "" >> ruff-format.txt
          echo "Exit code: ${EXIT_CODE}" >> ruff-format.txt
          exit ${EXIT_CODE}

      - name: Type check with mypy
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          mypy src/sparsetag.py src/cache_manager.py src/exceptions.py > mypy-report.txt 2>&1
          EXIT_CODE=$?
          echo "" >> mypy-report.txt
          echo "Exit code: ${EXIT_CODE}" >> mypy-report.txt
          exit ${EXIT_CODE}

      - name: Upload quality reports
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: quality-reports
          path: |
            ruff-lint.txt
            ruff-format.txt
            mypy-report.txt
          retention-days: 90

  sonarcloud:
    name: SonarCloud Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [detect-changes, quality]
    if: needs.detect-changes.outputs.code == 'true' || needs.detect-changes.outputs.config == 'true' || needs.detect-changes.outputs.workflows == 'true'
    environment: CGB
    permissions:
      contents: read
      pull-requests: read
    env:
      GITHUB_TOKEN: ${{ github.token }}
      SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-dev.txt

      - name: Run tests with coverage
        run: |
          pytest tests/ --cov=src --cov-report=xml --cov-report=term-missing -v

      - name: Verify SONAR_TOKEN is available
        id: check_sonar
        shell: bash
        run: |
          if [ -z "${SONAR_TOKEN}" ]; then
            echo "::warning::SONAR_TOKEN is empty. SonarCloud scan will be skipped."
            echo "available=false" >> $GITHUB_OUTPUT
          else
            echo "SONAR_TOKEN is set (masked)."
            echo "available=true" >> $GITHUB_OUTPUT
          fi
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

      - name: SonarCloud Scan
        if: steps.check_sonar.outputs.available == 'true'
        uses: SonarSource/sonarqube-scan-action@v7.0.0  # Unified action for SonarCloud/SonarQube

      - name: Upload coverage report
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: coverage-report
          path: coverage.xml
          retention-days: 90

  service-health-check:
    name: Service Health Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Check external service availability
        continue-on-error: true
        run: |
          echo "Checking service health..."

          # Check PyPI (accept 200)
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://pypi.org/simple/)
          if [[ "$STATUS" == "200" ]]; then
            echo "âœ… PyPI is reachable (HTTP $STATUS)"
          else
            echo "::warning::PyPI returned HTTP $STATUS"
          fi

          # Check Docker Hub (accept 200 or 3xx redirects)
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://hub.docker.com/)
          if [[ "$STATUS" =~ ^(200|3[0-9]{2})$ ]]; then
            echo "âœ… Docker Hub is reachable (HTTP $STATUS)"
          else
            echo "::warning::Docker Hub returned HTTP $STATUS"
          fi

          # Check SonarCloud (accept 200 or 3xx redirects)
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://sonarcloud.io/)
          if [[ "$STATUS" =~ ^(200|3[0-9]{2})$ ]]; then
            echo "âœ… SonarCloud is reachable (HTTP $STATUS)"
          else
            echo "::warning::SonarCloud returned HTTP $STATUS"
          fi

          # Check GHCR (accept 200, 3xx, or 405 - all indicate service is up)
          # Note: GHCR returns 405 for HEAD requests on root, which is normal
          STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://ghcr.io/)
          if [[ "$STATUS" =~ ^(200|3[0-9]{2}|405)$ ]]; then
            echo "âœ… GHCR is reachable (HTTP $STATUS)"
          else
            echo "::warning::GHCR returned HTTP $STATUS"
          fi

  doc-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: detect-changes
    if: needs.detect-changes.outputs.docs == 'true'
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8  # v6.0.1

      - name: Set up Node.js
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238  # v6.2.0
        with:
          node-version: '20'

      - name: Install markdown tools
        run: |
          npm install -g markdownlint-cli2@0.12.1
          npm install -g markdown-link-check@3.12.1

      - name: Lint markdown files
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          markdownlint-cli2 "**/*.md" "#node_modules" "#.venv" "#ScanResults" > markdownlint-report.txt 2>&1
          EXIT_CODE=$?

          # Show summary of errors in GitHub Actions UI
          if [ $EXIT_CODE -ne 0 ]; then
            echo "::warning::Markdownlint found style violations"
            echo "Summary:"
            grep "Summary:" markdownlint-report.txt || true
            echo ""
            echo "First 10 violations:"
            grep -E "^[A-Za-z].*MD[0-9]" markdownlint-report.txt | head -10 || true
            echo ""
            echo "Full report available in markdownlint-report.txt artifact"
          fi

          echo "" >> markdownlint-report.txt
          echo "Exit code: ${EXIT_CODE}" >> markdownlint-report.txt
          cat markdownlint-report.txt
          exit ${EXIT_CODE}

      - name: Check markdown links
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          find . -name "*.md" -not -path "*/node_modules/*" -not -path "*/.venv/*" -not -path "*/ScanResults/*" -print0 | xargs -0 -n1 markdown-link-check -c .markdown-link-check.json > markdown-link-check-report.txt 2>&1
          EXIT_CODE=$?

          # Show summary of errors in GitHub Actions UI
          if [ $EXIT_CODE -ne 0 ]; then
            echo "::warning::Found dead links in markdown files"
            echo "Dead links found:"
            grep -E "(FILE:.*\.md|âœ–.*|ERROR:.*dead)" markdown-link-check-report.txt | head -30 || true
            echo ""
            echo "Full report available in markdown-link-check-report.txt artifact"
          fi

          echo "" >> markdown-link-check-report.txt
          echo "Exit code: ${EXIT_CODE}" >> markdown-link-check-report.txt
          cat markdown-link-check-report.txt
          exit ${EXIT_CODE}

      - name: Upload documentation validation reports
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: doc-validation-reports
          path: |
            markdownlint-report.txt
            markdown-link-check-report.txt
          retention-days: 90

  test:
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 5
    needs: detect-changes
    if: needs.detect-changes.outputs.code == 'true' || needs.detect-changes.outputs.config == 'true' || needs.detect-changes.outputs.workflows == 'true'
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        python-version: ["3.10", "3.11", "3.12", "3.13"]

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8  # v6.0.1

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065  # v5.6.0
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-dev.txt

      - name: Test with pytest
        continue-on-error: true
        shell: bash
        run: |
          set +e  # Disable immediate exit on error
          pytest tests/ --cov=src --cov-report=xml --cov-report=term-missing --cov-fail-under=85 -v --junitxml=pytest-results.xml > pytest-output.txt 2>&1
          EXIT_CODE=$?
          echo "" >> pytest-output.txt
          echo "Exit code: ${EXIT_CODE}" >> pytest-output.txt
          exit ${EXIT_CODE}

      - name: Upload test results
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: |
            pytest-output.txt
            pytest-results.xml
            coverage.xml
          retention-days: 90

      - name: Check CODECOV_TOKEN availability
        id: check_codecov
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        shell: bash
        run: |
          if [ -z "${CODECOV_TOKEN}" ]; then
            echo "::warning::CODECOV_TOKEN is empty. Coverage upload will be skipped."
            echo "available=false" >> $GITHUB_OUTPUT
          else
            echo "CODECOV_TOKEN is set (masked)."
            echo "available=true" >> $GITHUB_OUTPUT
          fi
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload coverage to Codecov
        if: |
          matrix.os == 'ubuntu-latest' &&
          matrix.python-version == '3.11' &&
          steps.check_codecov.outputs.available == 'true'
        uses: codecov/codecov-action@671740ac38dd9b0130fbe1cec585b89eea48d3de  # v4
        continue-on-error: true  # Don't fail CI if CodeCov upload fails
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          fail_ci_if_error: false
          verbose: true

  docker-build-scan:
    name: Docker Build & Scan
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [detect-changes, quality, test]
    if: needs.detect-changes.outputs.code == 'true' || needs.detect-changes.outputs.config == 'true' || needs.detect-changes.outputs.workflows == 'true'
    permissions:
      contents: write  # Changed from 'read' to allow committing scan results
      packages: write
      security-events: write
      actions: read  # Required for SARIF upload

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8  # v6.0.1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}  # Ensure we can push back to repo

      - name: Extract version from pyproject.toml
        id: get_version
        run: |
          VERSION=$(python3 .github/scripts/extract-version.py)
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "Extracted version: ${VERSION}"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f  # v3.7.1

      - name: Build Docker image
        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83  # v6.18.0
        with:
          context: .
          push: false
          load: true
          tags: sparsetagging:${{ github.sha }}
          build-args: |
            APP_VERSION=${{ steps.get_version.outputs.version }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Run Trivy vulnerability scanner (SARIF)
        uses: aquasecurity/trivy-action@18f2510ee396bbf400402947b394f2dd8c87dbb0  # master
        continue-on-error: true  # Don't fail if vulnerabilities found, we want the SARIF file
        with:
          image-ref: sparsetagging:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          scanners: 'vuln,secret,config'  # Scan for vulnerabilities, secrets, and misconfigs
          exit-code: '0'  # Don't exit on findings, just create the report

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@cdefb33c0f6224e58673d9004f47f7cb3e328b89  # v3.27.6
        if: always()
        continue-on-error: true  # Will fail until Code Scanning is enabled in repo settings
        with:
          sarif_file: 'trivy-results.sarif'
          # To enable: Settings â†’ Code security â†’ Enable Code scanning

      - name: Upload Trivy SARIF report as artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: trivy-sarif-report
          path: trivy-results.sarif
          retention-days: 90

      - name: Run Trivy for full report (informational)
        uses: aquasecurity/trivy-action@18f2510ee396bbf400402947b394f2dd8c87dbb0  # master
        continue-on-error: true  # Don't fail build on vulnerabilities (base image issues)
        with:
          image-ref: sparsetagging:${{ github.sha }}
          format: 'table'
          output: 'trivy-report.txt'  # Save table report to file
          exit-code: '0'  # Report vulnerabilities but don't fail the build
          severity: 'CRITICAL,HIGH,MEDIUM'
          scanners: 'vuln,secret,config'  # Comprehensive scanning

      - name: Upload Trivy table report as artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: trivy-vulnerability-report
          path: trivy-report.txt
          retention-days: 90

      - name: Generate SBOM
        uses: aquasecurity/trivy-action@18f2510ee396bbf400402947b394f2dd8c87dbb0  # master
        with:
          image-ref: sparsetagging:${{ github.sha }}
          format: 'spdx-json'
          output: 'sbom.spdx.json'

      - name: Upload SBOM artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: sbom
          path: sbom.spdx.json
          retention-days: 90

      - name: Export Docker image as tarball
        run: |
          docker save sparsetagging:${{ github.sha }} -o sparsetagging-${{ github.sha }}.tar
          gzip sparsetagging-${{ github.sha }}.tar

      - name: Upload Docker image as artifact
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        with:
          name: docker-image
          path: sparsetagging-${{ github.sha }}.tar.gz
          retention-days: 30  # Shorter retention for large files

      - name: Generate artifact summary
        run: |
          cat > artifact-summary.md << 'EOF'
          # SparseTagging Docker Build Artifacts

          **Build Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Commit SHA:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## Available Artifacts

          ### 1. Docker Image (`docker-image`)
          - **File:** `sparsetagging-${{ github.sha }}.tar.gz`
          - **Size:** ~300MB (compressed)
          - **Usage:**
            ```bash
            # Download and load the image
            gunzip sparsetagging-${{ github.sha }}.tar.gz
            docker load -i sparsetagging-${{ github.sha }}.tar

            # Run the image
            docker run --rm sparsetagging:${{ github.sha }}

            # Interactive shell
            docker run --rm -it sparsetagging:${{ github.sha }} /bin/bash
            ```

          ### 2. Trivy Vulnerability Report (`trivy-vulnerability-report`)
          - **File:** `trivy-report.txt`
          - **Format:** Human-readable table
          - **Severities:** CRITICAL, HIGH, MEDIUM
          - **Scans:** Vulnerabilities, Secrets, Misconfigurations
          - **Usage:** Open in text editor to review findings

          ### 3. Trivy SARIF Report (`trivy-sarif-report`)
          - **File:** `trivy-results.sarif`
          - **Format:** SARIF (machine-readable)
          - **Usage:** Import into security tools, IDEs, or GitHub Security

          ### 4. SBOM - Software Bill of Materials (`sbom`)
          - **File:** `sbom.spdx.json`
          - **Format:** SPDX JSON
          - **Usage:** Compliance, license tracking, supply chain security
            ```bash
            # View with Trivy
            trivy sbom sbom.spdx.json

            # Validate SPDX
            java -jar spdx-tools.jar Verify sbom.spdx.json
            ```

          ## Image Details

          - **Base Image:** python:3.11-slim
          - **Architecture:** linux/amd64
          - **User:** sparsetag (UID 1000, non-root)
          - **Working Directory:** /app
          - **Python Version:** 3.11
          - **SparseTagging Version:** ${{ steps.get_version.outputs.version }}

          ## Testing the Image

          ```bash
          # Load the image
          docker load -i sparsetagging-${{ github.sha }}.tar

          # Verify it works
          docker run --rm sparsetagging:${{ github.sha }} python -c "import sparsetagging; print('OK')"

          # Run benchmarks (if available)
          docker run --rm sparsetagging:${{ github.sha }} python -m pytest --version
          ```

          ## Security Review

          1. **Review vulnerabilities:** Check `trivy-report.txt`
          2. **Check SARIF:** Import `trivy-results.sarif` to IDE
          3. **Verify SBOM:** Review `sbom.spdx.json` for dependencies
          4. **Test image:** Load and run security scans locally

          ## GitHub Container Registry

          On main branch, this image is also published to:
          ```
          ghcr.io/cgbraun/sparsetagging:latest
          ghcr.io/cgbraun/sparsetagging:${{ steps.get_version.outputs.version }}
          ```

          Pull and use:
          ```bash
          docker pull ghcr.io/cgbraun/sparsetagging:latest
          docker run --rm ghcr.io/cgbraun/sparsetagging:latest
          ```
          EOF

      - name: Upload artifact summary
        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b  # v4.5.0
        if: always()
        with:
          name: artifact-summary
          path: artifact-summary.md
          retention-days: 90

      - name: Download quality reports
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131  # v7.0.0
        if: github.ref == 'refs/heads/main'
        continue-on-error: true
        with:
          name: quality-reports
          path: ./quality-reports/

      - name: Download coverage report
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131  # v7.0.0
        if: github.ref == 'refs/heads/main'
        continue-on-error: true
        with:
          name: coverage-report
          path: ./coverage-report/

      - name: Download all test results
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131  # v7.0.0
        if: github.ref == 'refs/heads/main'
        continue-on-error: true
        with:
          pattern: test-results-*
          path: ./test-results/
          merge-multiple: false

      - name: Copy artifacts to scan directory (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          # Create timestamped directory
          TIMESTAMP=$(date -u +"%Y-%m-%d_%H-%M-%S")
          SCAN_DIR="ScanResults/${TIMESTAMP}"
          mkdir -p "${SCAN_DIR}"

          # Copy security artifacts
          cp trivy-results.sarif "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ trivy-results.sarif not found"
          cp trivy-report.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ trivy-report.txt not found"
          cp sbom.spdx.json "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ sbom.spdx.json not found"

          # Copy code quality reports
          cp quality-reports/ruff-lint.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ ruff-lint.txt not found"
          cp quality-reports/ruff-format.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ ruff-format.txt not found"
          cp quality-reports/mypy-report.txt "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ mypy-report.txt not found"
          cp coverage-report/coverage.xml "${SCAN_DIR}/" 2>/dev/null || echo "âš ï¸ coverage.xml not found"

          # Copy documentation validation reports (if they exist)
          if [ -d "doc-validation-reports" ]; then
            cp doc-validation-reports/markdownlint-report.txt "${SCAN_DIR}/" 2>/dev/null || true
            cp doc-validation-reports/markdown-link-check-report.txt "${SCAN_DIR}/" 2>/dev/null || true
          fi

          # Create test summary from all test matrix results
          cat > "${SCAN_DIR}/test-summary.md" << TEST_SUMMARY
          # Test Results Summary

          **Test Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Test Matrix:** Python 3.10, 3.11, 3.12, 3.13 Ã— Ubuntu + Windows

          ---

          ## Test Results by Environment

          TEST_SUMMARY

          # Parse test results from each matrix run
          if [ -d "test-results" ]; then
            for test_dir in test-results/test-results-*; do
              if [ -d "$test_dir" ]; then
                os_py=$(basename "$test_dir" | sed 's/test-results-//')
                echo "" >> "${SCAN_DIR}/test-summary.md"
                echo "### $os_py" >> "${SCAN_DIR}/test-summary.md"
                echo "" >> "${SCAN_DIR}/test-summary.md"

                if [ -f "$test_dir/pytest-output.txt" ]; then
                  # Extract key metrics
                  if grep -q "passed" "$test_dir/pytest-output.txt"; then
                    grep -E "(passed|failed|error|skipped|warnings summary)" "$test_dir/pytest-output.txt" | tail -5 >> "${SCAN_DIR}/test-summary.md"
                  else
                    echo "âš ï¸ Test output not parseable" >> "${SCAN_DIR}/test-summary.md"
                  fi
                  echo "" >> "${SCAN_DIR}/test-summary.md"
                fi
              fi
            done
          fi

          cat >> "${SCAN_DIR}/test-summary.md" << 'TEST_FOOTER'

          ---

          ## Full Test Outputs

          Individual test outputs for each environment are available in the \`test-results/\` directory.

          TEST_FOOTER

          # Save SCAN_DIR for next steps
          echo "SCAN_DIR=${SCAN_DIR}" >> $GITHUB_ENV

      - name: Generate scan results README (Python)
        if: github.ref == 'refs/heads/main'
        run: |
          python3 .github/scripts/build_scan_report.py \
            --scan-dir "${{ env.SCAN_DIR }}" \
            --commit-sha "${{ github.sha }}" \
            --workflow-run "${{ github.run_id }}" \
            --repository "${{ github.repository }}" \
            --branch "${{ github.ref_name }}"

          echo "âœ… Security artifacts saved to ${{ env.SCAN_DIR }}/"
          ls -lah "${{ env.SCAN_DIR }}/"
      - name: Commit and push security scan results (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          TIMESTAMP=$(date -u +"%Y-%m-%d_%H-%M-%S")

          git add ScanResults/

          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore(security): add scan results for ${TIMESTAMP}

          - Trivy vulnerability scan (SARIF and table formats)
          - SBOM in SPDX format
          - SonarCloud analysis links
          - Automated scan from commit ${{ github.sha }}

          ðŸ¤– Generated by GitHub Actions"

            git push
          fi

      - name: Verify Docker image exists
        if: github.ref == 'refs/heads/main'
        run: |
          if docker image inspect sparsetagging:${{ github.sha }} >/dev/null 2>&1; then
            echo "âœ… Docker image sparsetagging:${{ github.sha }} found"
            docker images sparsetagging:${{ github.sha }}
          else
            echo "::error::Docker image sparsetagging:${{ github.sha }} not found. Build may have failed."
            exit 1
          fi

      - name: Test Docker image (smoke test)
        if: github.ref == 'refs/heads/main'
        run: |
          echo "Running smoke test on Docker image..."

          # Save results to file for README
          SMOKE_TEST_RESULTS="docker-smoke-test-results.txt"

          # Test 1: Verify import works
          if docker run --rm sparsetagging:${{ github.sha }} python -c "import sparsetagging; print('âœ… Import successful')" > /tmp/test1.txt 2>&1; then
            cat /tmp/test1.txt | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST1=PASSED" >> "$SMOKE_TEST_RESULTS"
          else
            echo "âŒ Import failed" | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST1=FAILED" >> "$SMOKE_TEST_RESULTS"
          fi

          # Test 2: Verify version environment variable
          if docker run --rm sparsetagging:${{ github.sha }} python -c "import os; print(f'âœ… Version: {os.environ.get(\"APP_VERSION\", \"unknown\")}')" > /tmp/test2.txt 2>&1; then
            cat /tmp/test2.txt | tee -a "$SMOKE_TEST_RESULTS"
            VERSION_OUTPUT=$(cat /tmp/test2.txt | grep -oP 'Version: \K.*' || echo "unknown")
            echo "TEST2=PASSED" >> "$SMOKE_TEST_RESULTS"
            echo "VERSION=$VERSION_OUTPUT" >> "$SMOKE_TEST_RESULTS"
          else
            echo "âŒ Version check failed" | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST2=FAILED" >> "$SMOKE_TEST_RESULTS"
          fi

          # Test 3: Run basic functionality test
          if docker run --rm sparsetagging:${{ github.sha }} python -c "from sparsetagging import SparseTag, TagConfidence; st = SparseTag.create_random(100, ['Tag1', 'Tag2'], fill_percent=0.05); print(f'âœ… Created sparse matrix: {st.shape}')" > /tmp/test3.txt 2>&1; then
            cat /tmp/test3.txt | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST3=PASSED" >> "$SMOKE_TEST_RESULTS"
          else
            echo "âŒ Functionality test failed" | tee -a "$SMOKE_TEST_RESULTS"
            echo "TEST3=FAILED" >> "$SMOKE_TEST_RESULTS"
          fi

          echo "âœ… All smoke tests completed"
          echo "SMOKE_TEST_STATUS=COMPLETED" >> "$SMOKE_TEST_RESULTS"

      - name: Log in to GitHub Container Registry
        if: github.ref == 'refs/heads/main'
        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567  # v3.3.0
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Push to GHCR (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          docker tag sparsetagging:${{ github.sha }} ghcr.io/${{ github.repository_owner }}/sparsetagging:latest
          docker tag sparsetagging:${{ github.sha }} ghcr.io/${{ github.repository_owner }}/sparsetagging:${{ steps.get_version.outputs.version }}
          docker push ghcr.io/${{ github.repository_owner }}/sparsetagging:latest
          docker push ghcr.io/${{ github.repository_owner }}/sparsetagging:${{ steps.get_version.outputs.version }}
